{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the HDF5 file:\n",
      "['image', 'label']\n",
      "\n",
      "Contents of the datasets:\n",
      "Dataset: image\n",
      "[[[-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  ...\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]]\n",
      "\n",
      " [[-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  ...\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]]\n",
      "\n",
      " [[-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  ...\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  ...\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]]\n",
      "\n",
      " [[-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  ...\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]]\n",
      "\n",
      " [[-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  ...\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]\n",
      "  [-3.0839508 -3.0839508 -3.0839508 ... -3.0839508 -3.0839508 -3.0839508]]]\n",
      "\n",
      "\n",
      "Dataset: label\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"/code/zhang/SSL4MIS/data/BraTS2019/data/BraTS19_2013_0_1.h5\"  # Replace with the actual path to your h5 file\n",
    "\n",
    "try:\n",
    "    with h5py.File(file_path, \"r\") as h5_file:\n",
    "        # Print the keys of the datasets in the file\n",
    "        print(\"Keys in the HDF5 file:\")\n",
    "        print(list(h5_file.keys()))\n",
    "        \n",
    "        # Print the content of each dataset\n",
    "        print(\"\\nContents of the datasets:\")\n",
    "        for key, dataset in h5_file.items():\n",
    "            print(f\"Dataset: {key}\")\n",
    "            print(dataset[:])  # Print the entire dataset's content\n",
    "            print(\"\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while reading the HDF5 file: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the HDF5 file:\n",
      "['images']\n",
      "\n",
      "Contents of the datasets:\n",
      "Dataset: images\n",
      "[[[5 6]\n",
      "  [3 1]]\n",
      "\n",
      " [[8 3]\n",
      "  [1 7]]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"/code/zhang/SSL4MIS/data/new.h5\"  # Replace with the actual path to your h5 file\n",
    "\n",
    "try:\n",
    "    with h5py.File(file_path, \"r\") as h5_file:\n",
    "        # Print the keys of the datasets in the file\n",
    "        print(\"Keys in the HDF5 file:\")\n",
    "        print(list(h5_file.keys()))\n",
    "        \n",
    "        # Print the content of each dataset\n",
    "        print(\"\\nContents of the datasets:\")\n",
    "        for key, dataset in h5_file.items():\n",
    "            print(f\"Dataset: {key}\")\n",
    "            print(dataset[:])  # Print the entire dataset's content\n",
    "            print(\"\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while reading the HDF5 file: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random 3D array saved to /code/zhang/SSL4MIS/data/new.h5 under the key 'images'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generating a random 3D NumPy array with nested lists\n",
    "shape = (2, 2, 2)  # Specify the shape of the 3D array (replace with your desired shape)\n",
    "random_array = np.random.randint(0, 10, size=shape)\n",
    "\n",
    "# Creating the HDF5 file and saving the array\n",
    "file_path = \"/code/zhang/SSL4MIS/data/new.h5\"  # Replace with the desired path for the new h5 file\n",
    "dataset_name = 'images'  # The key in the HDF5 file where you want to save the data\n",
    "\n",
    "try:\n",
    "    with h5py.File(file_path, \"w\") as h5_file:\n",
    "        h5_file.create_dataset(dataset_name, data=random_array)\n",
    "    print(f\"Random 3D array saved to {file_path} under the key '{dataset_name}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while saving the random array to the HDF5 file: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
